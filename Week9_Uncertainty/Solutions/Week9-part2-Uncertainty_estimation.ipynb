{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FPfzMi-pDhOa"
   },
   "source": [
    "# Uncertainty estimation for images\n",
    "\n",
    "Spend the next 15min reading this paper\n",
    "https://arxiv.org/abs/1703.04977\n",
    "\n",
    "Now, let's implement it. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8AKe76-yzwcE"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda: 0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ILzWQvbJzwcP"
   },
   "source": [
    "## The data\n",
    "\n",
    "### Two-photon microscopy dataset of cortical axons\n",
    "\n",
    "As in lecture 3, this tutorial we use a dataset of cortical neurons with their corresponding segmentation binary labels.\n",
    "\n",
    "These images were collected using in-vivo two-photon microscopy from the mouse somatosensory cortex. To generate the 2D images, a max projection was used over the 3D stack. The labels are binary segmentation maps of the axons.\n",
    "\n",
    "Here we will use 100 [64x64] crops during training and validation. \n",
    "\n",
    "Bass, Cher, et al. \"Image synthesis with a convolutional capsule generative adversarial network.\" Medical Imaging with Deep Learning (2019).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jPU3l8ghzwcQ"
   },
   "outputs": [],
   "source": [
    "file_download_link = \"https://github.com/KCL-BMEIS/AdvancedMachineLearningCourse/blob/main/Week9_Uncertainty/Data/Week9_data.zip?raw=true\"\n",
    "!wget -O Week9_data.zip --no-check-certificate \"$file_download_link\"\n",
    "!unzip -q Week9_data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EbBJ0Kb_zwcW"
   },
   "outputs": [],
   "source": [
    "#load modules\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from Data.AxonDataset import AxonDataset\n",
    "import torch.nn as nn\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import time\n",
    "import torch.nn.functional as F\n",
    "import torchvision.utils as vutils\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "bB5K5ZAxzwcb",
    "outputId": "2c37a5bd-b541-498d-85ea-4f61c5219168"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Setting parameters\n",
    "timestr = time.strftime(\"%d%m%Y-%H%M\")\n",
    "__location__ = os.path.realpath(\n",
    "    os.path.join(os.getcwd(), os.path.dirname('__file__')))\n",
    "\n",
    "print(__location__)\n",
    "\n",
    "path = os.path.join(__location__,'results')\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "    \n",
    "# Define your batch_size\n",
    "batch_size = 32\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ut9--w9pzwcf"
   },
   "source": [
    "### Creating a dataloader\n",
    "\n",
    "In this example, a custom dataloader was created, and we import it from `AxonDataset.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NSt8IE8uzwch"
   },
   "outputs": [],
   "source": [
    "\n",
    "#First we create a dataloader for our example dataset- two photon microscopy with axons\n",
    "axon_dataset = AxonDataset(data_name='org64', type='train', folder='/content/Data')\n",
    "\n",
    "indices = list(range(len(axon_dataset)))  # start with all the indices in training set\n",
    "split = int(len(indices)*0.2)  # define the split size\n",
    "\n",
    "# Get indices for train and validation datasets, and split the data\n",
    "validation_idx = np.random.choice(indices, size=split, replace=False)\n",
    "train_idx = list(set(indices) - set(validation_idx))\n",
    "\n",
    "\n",
    "# feed indices into the sampler\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "validation_sampler = SubsetRandomSampler(validation_idx)\n",
    "\n",
    "# Create a dataloader instance \n",
    "train_loader = torch.utils.data.DataLoader(axon_dataset, batch_size = batch_size,\n",
    "                                           sampler=train_sampler) \n",
    "val_loader = torch.utils.data.DataLoader(axon_dataset, batch_size = batch_size,\n",
    "                                        sampler=validation_sampler) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EGnBr2yezwcl"
   },
   "source": [
    "\n",
    "## The network\n",
    "\n",
    "Let's implement a UNET as per lecture 3. \n",
    "\n",
    "Ronneberger, Olaf, Philipp Fischer, and Thomas Brox. \"U-net: Convolutional networks for biomedical image segmentation.\" International Conference on Medical image computing and computer-assisted intervention. Springer, Cham, 2015.\n",
    "\n",
    "First we define a layer `double_conv` that performs 2 sets of convolution followed by ReLu.This is set up as a `nn.Sequential(` block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bs6ZYQ-czwcm"
   },
   "outputs": [],
   "source": [
    "# define U-net\n",
    "def double_conv(in_channels, out_channels, padding=1):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=padding),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=padding),\n",
    "        nn.ReLU(inplace=True)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gXByC6xgzwcq"
   },
   "source": [
    "We then define our U-net network.\n",
    "\n",
    "We first initialise all the different layers in the network in `__init__`:\n",
    "1. `self.dconv_down1` is a double convolutional layer (defined above)\n",
    "2. `self.maxpool` is a max pooling layer that is used to reduce the size of the input, and increase the receptive field\n",
    "3. `self.upsample` is an upsampling layer that is used to increase the size of the input\n",
    "4. `dropout` is a dropout layer that is applied to regularise the training\n",
    "5. `dconv_up4` is also a double convolutional layer- note that it takes in additional channels from previous layers (i.e. the skip connections).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TT-0wXGJzwcr"
   },
   "outputs": [],
   "source": [
    "\n",
    "class UNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.dconv_down1 = double_conv(1, 32)\n",
    "        self.dconv_down2 = double_conv(32, 64)\n",
    "        self.dconv_down3 = double_conv(64, 128)\n",
    "        self.dconv_down4 = double_conv(128, 256)\n",
    "        self.dconv_down5 = double_conv(256, 512)\n",
    "\n",
    "        self.maxpool = nn.MaxPool2d(2)\n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        self.dropout = nn.Dropout2d(0.3)\n",
    "        self.dconv_up4 = double_conv(256 + 512, 256)\n",
    "        self.dconv_up3 = double_conv(128 + 256, 128)\n",
    "        self.dconv_up2 = double_conv(128 + 64, 64)\n",
    "        self.dconv_up1 = double_conv(64 + 32, 32)\n",
    "        \n",
    "        \n",
    "        self.dconv_up4_uncert = double_conv(256 + 512, 256)\n",
    "        self.dconv_up3_uncert = double_conv(128 + 256, 128)\n",
    "        self.dconv_up2_uncert = double_conv(128 + 64, 64)\n",
    "        self.dconv_up1_uncert = double_conv(64 + 32, 32)\n",
    "\n",
    "        self.conv_last = nn.Conv2d(32, 1, 1)\n",
    "        self.conv_last_uncert = nn.Conv2d(32, 1, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        #######   ENCODER ###############\n",
    "        \n",
    "        conv1 = self.dconv_down1(x)\n",
    "        conv1 = self.dropout(conv1)\n",
    "        x = self.maxpool(conv1)\n",
    "\n",
    "        # implement encoder layers conv2, conv3 and conv4\n",
    "        \n",
    "        conv2 = self.dconv_down2(x)\n",
    "        conv2 = self.dropout(conv2)\n",
    "        x = self.maxpool(conv2)\n",
    "\n",
    "        conv3 = self.dconv_down3(x)\n",
    "        conv3 = self.dropout(conv3)\n",
    "        x = self.maxpool(conv3)\n",
    "\n",
    "        conv4 = self.dconv_down4(x)\n",
    "        conv4 = self.dropout(conv4)\n",
    "        x = self.maxpool(conv4)\n",
    "\n",
    "        # implement bottleneck\n",
    "        \n",
    "        conv5 = self.dconv_down5(x)\n",
    "        conv5 = self.dropout(conv5)\n",
    "       \n",
    "        #######   DECODER ###############\n",
    "        \n",
    "        # Implement the decoding layers\n",
    "        \n",
    "        deconv4 = self.upsample(conv5)\n",
    "        deconv4 = torch.cat([deconv4, conv4], dim=1)  \n",
    "        deconv4  = self.dconv_up4(deconv4)\n",
    "        deconv4 = self.dropout(deconv4)\n",
    "\n",
    "        deconv3 = self.upsample(deconv4 )       \n",
    "        deconv3 = torch.cat([deconv3, conv3], dim=1)\n",
    "        deconv3 = self.dconv_up3(deconv3)\n",
    "        deconv3 = self.dropout(deconv3)\n",
    "\n",
    "        deconv2 = self.upsample(deconv3)      \n",
    "        deconv2 = torch.cat([deconv2, conv2], dim=1)\n",
    "        deconv2 = self.dconv_up2(deconv2)\n",
    "        deconv2 = self.dropout(deconv2)\n",
    "       \n",
    "        deconv1 = self.upsample(deconv2)   \n",
    "        deconv1 = torch.cat([deconv1, conv1], dim=1)\n",
    "        deconv1 = self.dconv_up1(deconv1)\n",
    "        deconv1 = self.dropout(deconv1)\n",
    "\n",
    "        #---------------------------------------------------------------------------------------------------------------------\n",
    "        out1 = torch.sigmoid(self.conv_last(deconv1))\n",
    "        \n",
    "        deconv4_uncert = self.upsample(conv5)\n",
    "        deconv4_uncert = torch.cat([deconv4_uncert, conv4], dim=1)  \n",
    "        deconv4_uncert  = self.dconv_up4_uncert(deconv4_uncert)\n",
    "        deconv4_uncert = self.dropout(deconv4_uncert)\n",
    "\n",
    "        deconv3_uncert = self.upsample(deconv4_uncert )       \n",
    "        deconv3_uncert= torch.cat([deconv3_uncert, conv3], dim=1)\n",
    "        deconv3_uncert = self.dconv_up3_uncert(deconv3_uncert)\n",
    "        deconv3_uncert = self.dropout(deconv3_uncert)\n",
    "\n",
    "        deconv2_uncert = self.upsample(deconv3_uncert)      \n",
    "        deconv2_uncert = torch.cat([deconv2_uncert, conv2], dim=1)\n",
    "        deconv2_uncert = self.dconv_up2_uncert(deconv2_uncert)\n",
    "        deconv2_uncert = self.dropout(deconv2_uncert)\n",
    "       \n",
    "        deconv1_uncert = self.upsample(deconv2_uncert)   \n",
    "        deconv1_uncert = torch.cat([deconv1_uncert, conv1], dim=1)\n",
    "        deconv1_uncert = self.dconv_up1_uncert(deconv1_uncert)\n",
    "        deconv1_uncert = self.dropout(deconv1_uncert)\n",
    "\n",
    "        #---------------------------------------------------------------------------------------------------------------------\n",
    "        out2 = self.conv_last_uncert(deconv1_uncert)\n",
    "\n",
    "        return out1, out2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l-GKtfb2zwcu"
   },
   "source": [
    "To save time we initialise the network with a previously trained network by loading the weights\n",
    "\n",
    "*for practical reasons training this network from scratch will take too long, and require large computational resources*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Kb0RJvl-zwcv"
   },
   "outputs": [],
   "source": [
    "# initialise network - and load weights\n",
    "net = UNet()\n",
    "\n",
    "#adding line to support GPU use (where available)\n",
    "net=net.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BuR-uEXgzwcy"
   },
   "source": [
    "## The Loss Function\n",
    "We next define a Dice loss as a tracking metric, and the CE uncertainty loss as the optimisation metric. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AMDb1hSbzwcz"
   },
   "outputs": [],
   "source": [
    "# dice loss\n",
    "def dice_coeff(pred, target):\n",
    "    \"\"\"This definition generalize to real valued pred and target vector.\n",
    "    This should be differentiable.\n",
    "    pred: tensor with first dimension as batch\n",
    "    target: tensor with first dimension as batch\n",
    "    \"\"\"\n",
    "\n",
    "    smooth = 1.\n",
    "    epsilon = 10e-8\n",
    "\n",
    "    # have to use contiguous since they may from a torch.view op\n",
    "    iflat = pred.contiguous().view(-1)\n",
    "    tflat = target.contiguous().view(-1)\n",
    "    intersection = (iflat * tflat).sum()\n",
    "\n",
    "    A_sum = torch.sum(iflat * iflat)\n",
    "    B_sum = torch.sum(tflat * tflat)\n",
    "\n",
    "    dice = (2. * intersection + smooth) / (A_sum + B_sum + smooth)\n",
    "    dice = dice.mean(dim=0)\n",
    "    dice = torch.clamp(dice, 0, 1.0-epsilon)\n",
    "\n",
    "    return  dice\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ud2mv8Clzwc2"
   },
   "outputs": [],
   "source": [
    "def ce_with_uncertainty(pred,log_var, target, regul=1, epsilon=0.005):\n",
    "    lab_smoothing=0.00001\n",
    "    ce_loss = - torch.log(pred+lab_smoothing) * target - torch.log((1-pred)+lab_smoothing) * (1-target) \n",
    "    total_loss = 0.5*ce_loss/(torch.exp(log_var)+epsilon) + regul*0.5*torch.log(torch.exp(log_var) + epsilon)\n",
    "    return total_loss.mean()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iIPgMqnAzwc4"
   },
   "source": [
    "Here the penalty term `lab_smoothing` is added to prevent penalising very harshly any mistake by the network.\n",
    "\n",
    "As before, we define the optimiser to train our network - here we use Adam.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "93eIrjYszwc5"
   },
   "outputs": [],
   "source": [
    "#define your optimiser\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, net.parameters()), lr=1e-04, betas=(0.5, 0.999))\n",
    "optimizer.zero_grad()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tk_82y80zwc7"
   },
   "source": [
    "## Training and evaluating the network\n",
    "We next train and evaluate our network \n",
    "\n",
    "note that the results are saved to a folder \\results - so please check that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f5w2--Buzwc8"
   },
   "outputs": [],
   "source": [
    "epochs=300\n",
    "save_every=50\n",
    "all_error = np.zeros(0)\n",
    "all_error_L1 = np.zeros(0)\n",
    "all_error_dice = np.zeros(0)\n",
    "all_dice = np.zeros(0)\n",
    "all_val_dice = np.zeros(1)\n",
    "all_val_error = np.zeros(0)\n",
    "import os\n",
    "cwd = os.getcwd()\n",
    "path= cwd + '/results'\n",
    "\n",
    "t0 = time.time()\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    ##########\n",
    "    # Train\n",
    "    ##########\n",
    "    mean_error = np.zeros(0)\n",
    "    mean_dice = np.zeros(0)\n",
    "    for i, (data, label) in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        label= label.to(device)\n",
    "        # setting your network to train will ensure that parameters will be updated during training, \n",
    "        # and that dropout will be used\n",
    "        net.train()\n",
    "        net.zero_grad()\n",
    "\n",
    "        target_real = torch.ones(data.size()[0])\n",
    "        batch_size = data.size()[0]\n",
    "        pred, log_var = net(data)\n",
    "\n",
    "        # dice loss = 1-dice_coeff\n",
    "        # ----------------------------------------------- task 3 ------------------------------------------------------------\n",
    "        # Task 3: change loss function here\n",
    "        err = ce_with_uncertainty(pred, log_var, label, regul=3, epsilon=(0.001-0.0009*epoch/epochs))\n",
    "        # -------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "        dice_value = dice_coeff(pred, label).item()\n",
    "\n",
    "        err.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        error = err.item()\n",
    "        mean_error = np.append(mean_error, error)\n",
    "        mean_dice = np.append(mean_dice, dice_value)\n",
    "\n",
    "\n",
    "    # #############\n",
    "    # # Validation\n",
    "    # #############\n",
    "    if epoch % 5 == 0:\n",
    "        time_elapsed = time.time() - t0\n",
    "        error = err.item()\n",
    "\n",
    "        print('[{:d}/{:d}] Elapsed_time: {:.0f}m{:.0f}s Loss: {:.4f} Dice: {:.4f}'\n",
    "              .format(epoch, epochs, time_elapsed // 60, time_elapsed % 60,\n",
    "                      np.mean(mean_error), np.mean(mean_dice)))\n",
    "        t0 = time.time()\n",
    "        \n",
    "    mean_error = np.zeros(0)\n",
    "    mean_dice = np.zeros(0)\n",
    "    for i, (data, label) in enumerate(val_loader):\n",
    "        data = data.to(device)\n",
    "        label= label.to(device)\n",
    "        net.eval()\n",
    "        batch_size = data.size()[0]\n",
    "\n",
    "        data, label = Variable(data), Variable(label)\n",
    "        pred, log_var = net(data)\n",
    "        \n",
    "        err = 1-dice_coeff(pred, label)\n",
    "\n",
    "        # compare generated image to data-  metric\n",
    "        dice_value = dice_coeff(pred, label).item()\n",
    "        if epoch % 100 == 0:\n",
    "            if i == 0:\n",
    "                vutils.save_image(data.data, '%s/epoch_val_data.png' % (path),\n",
    "                                  normalize=True)\n",
    "                vutils.save_image(label.data, '%s/epoch_val_label.png' % (path),\n",
    "                                  normalize=True)\n",
    "                vutils.save_image(pred.data, '%s/epoch_val_pred.png' % (path),\n",
    "                                  normalize=True)\n",
    "                vutils.save_image(torch.exp(log_var).data, '%s/epoch_val_aleatoric_uncert.png' % (path),\n",
    "                                  normalize=True)\n",
    "\n",
    "        error = err.item()\n",
    "        mean_error = np.append(mean_error, error)\n",
    "        mean_dice = np.append(mean_dice, dice_value)\n",
    "\n",
    "    all_val_error = np.append(all_val_error, np.mean(mean_error))\n",
    "    all_val_dice = np.append(all_val_dice, np.mean(mean_dice))\n",
    "    \n",
    "    \n",
    "    num_it_per_epoch_train = ((train_loader.dataset.x_data.shape[0] * (1 - 0.2)) // (\n",
    "            save_every * batch_size)) + 1\n",
    "    epochs_train = np.arange(1,all_error.size+1) / num_it_per_epoch_train\n",
    "    epochs_val = np.arange(0,all_val_dice.size)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(epochs_val, all_val_dice, label='dice_val')\n",
    "    plt.xlabel('epochs')\n",
    "    plt.legend()\n",
    "    plt.title('Dice score')\n",
    "    plt.savefig(path + '/dice_val.png')\n",
    "    plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c7zNJrimzwc9"
   },
   "source": [
    "## Dropout Sampling\n",
    "\n",
    "Now, let's sample from the model with dropout at test time. A few tricks are neede though...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OyQIroeAdfEk"
   },
   "outputs": [],
   "source": [
    "def enable_dropout(model):\n",
    "  for m in model.modules():\n",
    "    if m.__class__.__name__.startswith('Dropout'):\n",
    "      m.train()\n",
    "  \n",
    "# #############\n",
    "# # Epistemic Evaluation\n",
    "# #############\n",
    "dropout_samples = 100\n",
    "mean_error = np.zeros(0)\n",
    "mean_dice = np.zeros(0)\n",
    "samples_array = torch.zeros(size=(dropout_samples, 32, 1, 64, 64), dtype=torch.float)\n",
    "samples_logvar = torch.zeros(size=(dropout_samples, 32, 1, 64, 64), dtype=torch.float)\n",
    "for i, (data, label) in enumerate(val_loader):\n",
    "  for sample in range(dropout_samples):\n",
    "    data = data.to(device)\n",
    "    label= label.to(device)\n",
    "    enable_dropout(net)\n",
    "    batch_size = data.size()[0]\n",
    "\n",
    "    data, label = Variable(data), Variable(label)\n",
    "    pred, log_var = net(data)\n",
    "    \n",
    "    if pred.data.size()[0] == 32:\n",
    "      samples_array[sample, :, :, :, :] = pred.data.detach().cpu()\n",
    "      samples_logvar[sample, :, :, :, :] = torch.exp(log_var.data.detach().cpu())\n",
    "\n",
    "\n",
    "  net.eval()\n",
    "  pred, log_var = net(data)\n",
    "\n",
    "  # Calculate the variance resulting from multiple dropout samples, per pixel\n",
    "  epistemic_var = torch.var(samples_array, axis=0)\n",
    "  mean_pred = torch.mean(samples_array, axis=0)\n",
    "  mean_logval = torch.mean(samples_logvar, axis=0)\n",
    "  if i == 0:\n",
    "    vutils.save_image(data.data, '%s/epoch_val_data.png' % (path),\n",
    "                      normalize=True)\n",
    "    vutils.save_image(label.data, '%s/epoch_val_label.png' % (path),\n",
    "                      normalize=True)\n",
    "    vutils.save_image(mean_pred, '%s/epoch_val_pred.png' % (path),\n",
    "                      normalize=True)\n",
    "    vutils.save_image(mean_logval, '%s/epoch_val_aleatoric_uncert.png' % (path),\n",
    "                      normalize=False)\n",
    "    vutils.save_image(epistemic_var, '%s/epoch_val_epistemic_unc.png' % (path),\n",
    "                      normalize=False)\n",
    "  else: \n",
    "    break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IK0P1t-kNkb3"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Uncertainty_estimation_(Images)_final.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
