{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "hide_code_all_hidden": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "1.2.PyTorch_Foundations.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "sbHg-UspyY2y",
        "JD4KqrZUyY23",
        "853FW_kvEIg-",
        "s3bPA472EOML",
        "nPg1yD1FCcjo",
        "bWc1EpwQV00i"
      ],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "hideCode": false,
        "hidePrompt": false,
        "id": "B-nzwpONyY1x"
      },
      "source": [
        "# PyTorch Basics\n",
        "\n",
        "Tutorial by Abdulah Fawaz and Emma Robinson"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hideCode": false,
        "hidePrompt": false,
        "id": "jOzoBxLfyY10"
      },
      "source": [
        "## 1. PyTorch Tensors\n",
        "<a id='tensors'></a>\n",
        "\n",
        "PyTorch is a lot like numpy. A lot of operations used to manipulate numpy arrays have their counterparts in pytorch and numpy arrays can be converted to and from pytorch *tensors*. PyTorch arrays are given the more proper mathematical name of tensors (see e.g tensorflow). In terms of practical usage pytorch tensors can be manipulated very similarly to NumPy’s ndarrays, with the addition being that Tensors can also be used on a GPU to accelerate computing.\n",
        "\n",
        "Below are some examples. Let us begin by importing torch and numpy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hideCode": false,
        "hidePrompt": false,
        "id": "KNpbrURnyY11"
      },
      "source": [
        "import torch #import torch\n",
        "import numpy as np\n",
        "\n",
        "device = torch.device(\"cuda: 0\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hideCode": false,
        "hidePrompt": false,
        "id": "Bm1d0tsFyY13"
      },
      "source": [
        "Generating a random array of size 2x2x2: NumPy vs PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hideCode": false,
        "hidePrompt": false,
        "id": "eb6Uiw22yY14"
      },
      "source": [
        "# Numpy\n",
        "numpy_random_arr = np.random.rand(2,2,2)\n",
        "numpy_random_arr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hideCode": false,
        "hidePrompt": false,
        "id": "WNvtO1_PyY17"
      },
      "source": [
        "# PyTorch\n",
        "torch_random_arr = torch.rand(2,2,2)\n",
        "torch_random_arr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hideCode": false,
        "hidePrompt": false,
        "id": "YvEYvgVryY1-"
      },
      "source": [
        "They are indexed in the same way"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hideCode": false,
        "hidePrompt": false,
        "id": "w47iT48iyY1_"
      },
      "source": [
        "torch_random_arr[0,0,0], numpy_random_arr[0,0,0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hideCode": false,
        "hidePrompt": false,
        "id": "pF-lnf77yY2B"
      },
      "source": [
        "and can be reshaped using reshape functions ..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hideCode": false,
        "hidePrompt": false,
        "id": "0Uk2DrqgyY2C"
      },
      "source": [
        "torch_random_arr = torch_random_arr.reshape(4,2)\n",
        "print(torch_random_arr.size())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hideCode": false,
        "hidePrompt": false,
        "id": "UYy6RdEkyY2E"
      },
      "source": [
        "numpy_random_arr = np.reshape(numpy_random_arr, [4,2])\n",
        "print(numpy_random_arr.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hideCode": false,
        "hidePrompt": false,
        "id": "HTNZZSr1yY2G"
      },
      "source": [
        "Converting to and from numpy arrays is easy:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hideCode": false,
        "hidePrompt": false,
        "id": "KEZJCW55yY2H"
      },
      "source": [
        "a = np.array([[1,2],[3,4]]) # make a numpy array\n",
        "\n",
        "a_torch = torch.from_numpy(a) #converting to a torch Tensor from a numpy array\n",
        "print(a_torch) \n",
        "\n",
        "a_np = a_torch.numpy() # converting to a numpy array from a torch Tensor\n",
        "print(a_np)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hideCode": false,
        "hidePrompt": false,
        "id": "ltN81xK3yY2K"
      },
      "source": [
        "Other basic functions such as torch.diag, torch.cat (concatenate), torch.matmul work similarly to their numpy equivalents. <br>\n",
        "As always, when looking for a function **check the [documentation](https://stackoverflow.com/questions/25692293/inserting-a-link-to-a-webpage-in-an-ipython-notebook)** and consider running through the [official pytorch tutorial](https://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html) on tensor manipulation "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hideCode": false,
        "hidePrompt": false,
        "id": "-DAGrHkoyY2L"
      },
      "source": [
        "Note like in numpy, the data type (dtype) of an object is important.\n",
        "PyTorch Tensors types - just like in any other programming language - depend on whether they are storing integers, floating points or bools, and in how many bits. Often, it is important to make sure tensors are of the right / matching type when performing operations on them.\n",
        "<br>\n",
        "See https://pytorch.org/docs/stable/tensors.html for a list of dtypes and what they are called in PyTorch.\n",
        "\n",
        "Changing torch tensor type is simple:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hideCode": false,
        "hidePrompt": false,
        "id": "MRafLBDryY2L"
      },
      "source": [
        "print(a_torch)\n",
        "print(a_torch.to(torch.double)) #casts the int32 dtype tensor into a 64 bit float dtype tensor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hideCode": false,
        "hidePrompt": false,
        "id": "7qCruwnDyY2N"
      },
      "source": [
        "Finally, tensor reshaping/resizing can be completed using torch.view:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hideCode": false,
        "hidePrompt": false,
        "id": "dQG-E86ayY2O"
      },
      "source": [
        "x = torch.randn(3, 3)\n",
        "\n",
        "y = x.view(1, -1)  # the size -1 is inferred from other dimensions\n",
        "print(x.size(), y.size())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hideCode": false,
        "hidePrompt": false,
        "id": "SiQE9hC3yY2Q"
      },
      "source": [
        "\n",
        "### Exercise 1. Basic Tensor Operations\n",
        "\n",
        "There is some streamlining of operations in pytorch relative to numpy which can simplify code development. For example, compare here the multiplications of two arrrays using broadcasting.\n",
        "\n",
        "1. Generate two random numpy arrays, **a** and __b__ of sizes [12,5] and [3,5,20] \n",
        "\n",
        "\n",
        "2. Find the matrix product **a** $\\cdot$ __b__ using broadcasting.\n",
        "    **hint: may need to reshape a first:**  multiplication of 3D arrays involves [multiplication of stacks of 2D matrices]( https://www.geeksforgeeks.org/numpy-3d-matrix-multiplication/). Therefore, the final result should be of shape (3,12,20), since multiplication of a ($12 \\times 5$) and a ($5 \\times 20$) matrix returns shape ($12 \\times 20$) \n",
        "    \n",
        "    \n",
        "3. Convert **a** and __b__ into PyTorch Tensors and perform direct multiplication (without reshaping).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hideCode": false,
        "hidePrompt": false,
        "id": "v0x3evfbyY2Q"
      },
      "source": [
        "# STUDENTS CODE HERE\n",
        "# 1.1. create numpy arrays a and b\n",
        "a = None\n",
        "b = None\n",
        "# 1.2 find the matrix product of a and b through broadcasting, you will need to reshape a first\n",
        "numpy_mult=None\n",
        "\n",
        "# 1.3 do the same thing but for pytorch tensors - no reshaping will be required\n",
        "a_t = None\n",
        "b_t = None\n",
        "pytorch_mult=None\n",
        "\n",
        "print(pytorch_mult)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hideCode": false,
        "hidePrompt": false,
        "id": "9k6cvCGayY2S"
      },
      "source": [
        "## 2. Autograd: automatic differentiation\n",
        "\n",
        "As you might imagine, it is not the similarities between the two that we are interested in, but what makes torch Tensors relevant to machine learning. The most significant and relevant difference is that PyTorch Tensors also have an associated *gradient*. It is this that is used to perform the optimization that machine learning is based on. \n",
        "\n",
        "The gradient of a pytorch tensor is stored as its ```.grad``` attribute. All pytorch tensors have this even if it is not apparent nor used. In such a case it would be set to \"None\". \n",
        "\n",
        "All PyTorch tensors have another boolean attribute ```requires_grad``` that indicates whether pytorch *needs* to track and store its gradient or whether it is simply a static tensor. By default, requires_grad is set to False.\n",
        "When we later construct neural networks from the torch.nn neural network module, requires_grad will be automatically set to True for the relevant learning parameters so it is not something you should generally worry about setting manually.\n",
        "\n",
        "In addition the attribute ```grad_fn```: This is the backward function used to calculate the gradient.\n",
        "\n",
        "### Exercise2 - run backpropagation using autograd for simple function\n",
        "\n",
        "For example, let's observe gradient estimation for a simple function $L = \\frac{1}{N} \\sum_{i}\\sum_j (2x_{ij}+3)^2  $ operating on a matrix $\\mathbf{X}$ with $N$ elements.\n",
        "\n",
        "**To do** run this code and check the outputs. Consider also printing out the `is_leaf` and requires_grad attributes for each tensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hideCode": false,
        "hidePrompt": false,
        "id": "ZN87ikS8yY2T"
      },
      "source": [
        "X = torch.ones(5,5, requires_grad=True) # generate a random Tensor\n",
        "\n",
        "print('Initial gradient:', X.grad) # check its gradient - the result is None\n",
        "\n",
        "y=2*X+3\n",
        "z=y*y\n",
        "out = z.mean()\n",
        "\n",
        "\n",
        "out.backward()\n",
        "print('grad:', X.grad) \n",
        "print('grad_fn:', out.grad_fn)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hideCode": false,
        "hidePrompt": false,
        "id": "fpEz0LKxyY2V"
      },
      "source": [
        "**(Optionally) prove this is correct using the chain rule.**\n",
        "\n",
        "Do this now and then try repeating the process for another simple function, of your choice. Try also generating $\\mathbf{X}$ in different ways, using torch random number generators for example.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hideCode": false,
        "hidePrompt": false,
        "id": "WbE1nJUIyY2W"
      },
      "source": [
        "In practice the ```autograd``` package provides an engine to perform backpropagation. As variables and operations are defined it sets up a dynamic computational graph in the same sense as we saw in our first lecture. In this, the leaves of the graph are input tensors, defined using initialisation operations such as those shown [above](#tensors), and identified using the attribute ```is_leaf==True```. Roots are output tensors. Gradients are then calculated by tracing the graph from the root to the leaf and multiplying every gradient in the way using the chain rule. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hideCode": false,
        "hidePrompt": false,
        "id": "5UStkdQoyY2W"
      },
      "source": [
        "## 3. PyTorch NN Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hideCode": false,
        "hidePrompt": false,
        "id": "ZJ5S7QobyY2X"
      },
      "source": [
        "import torch.nn as nn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hideCode": false,
        "hidePrompt": false,
        "id": "Biz88_YGyY2Z"
      },
      "source": [
        "The torch.nn module contains all the functions you will need to build a neural network. For example, here is the definition of a Linear Layer (the $Z=WX$ component of a fully connected network, using the terminology from our first lecture)\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?id=1sSOfwz1iVdXGA-rmeJnOl--4DrMKij6e\" alt=\"Drawing\" style=\"width: 800px;\"/>\n",
        "\n",
        "\n",
        "This shows that we must pass it the total number of input (columns of $\\mathbf{W}$ using notation of first lecture) and output features (the rows of $\\mathbf{W}$ using notation of first lecture)$. It also has `bias=True` by default. \n",
        "\n",
        "Here we will create a linear layer with  3x100x100 = 300000 input features and 10 output features and will apply it to a flattened input image of original shape (3,100,100)\n",
        "\n",
        "**Note** PyTorch only supports gradient estimation for can only be calculated for floating point tensors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hideCode": false,
        "hidePrompt": false,
        "id": "HVzdbjX5yY2w"
      },
      "source": [
        "import torch.nn as nn # importing torch.nn \n",
        "\n",
        "# the first dimension has size N where N is the number of images. \n",
        "#here it is simply 1\n",
        "\n",
        "input_image = torch.randint(0, 255, (1, 3,100,100)) # our random image. \n",
        "input_image = input_image.to(torch.float) # NOTE! tensors must be cast as float \n",
        "\n",
        "fc_operation = nn.Linear(30000, 10) # defining our fully connected Linear layer\n",
        "\n",
        "reshaped_input_image = input_image.reshape(input_image.size(0), -1) #reshaping input image \n",
        "\n",
        "print('input image shape ', input_image.shape,'reshaped_input_image shape' , reshaped_input_image.shape)\n",
        "result = fc_operation(reshaped_input_image) \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hideCode": false,
        "hidePrompt": false,
        "id": "pvPa3X4VyY2y"
      },
      "source": [
        "Note, goal with the reshape operation is to unravel the image into a single vector. As you may be accustomed with in numpy, reshape dimensions of (input_image.size(0), -1) reshape the image into a vector, where -1 tells pytorch to, essentially, figure out itself what should be the corresponding size of this dimension given the input. \n",
        "\n",
        "Further, input_image.size(0) returns the size of the first dimension of our image array, which represents the number of examples. Here, it is one but in real examples, there can be a variable number of images used in each batch. By defining the first dimension of the reshape size(0) it ensures that we unravel each image independently, to return an $N \\times 300000$ array: ```reshaped_input_image```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sbHg-UspyY2y"
      },
      "source": [
        "## 4. nn.Functional\n",
        "\n",
        "As you will see as we go forward most PyTorch layers can be implemented either as a `torch.nn.Module` object or as a `torch.nn.Functional` function. So which should you use? \n",
        "\n",
        "Essentially,  `nn.functional` provides building block functions (e.g. layers / activations) in form of functions. This means that they can be directly called on the input rather than defining the object. \n",
        "\n",
        "In cases, where we have weights or other trainable parameters e.g. linear of convolutional layers, states which behave differently at train time and test time (for example dropout and Batch Norm ), then we should use `nn.Module` objects. The whole point is that these define a class to hold the data structure, and make (e.g. convolutional) operations member functions.\n",
        "\n",
        "On the other hand, in cases where no state or weights are required, `nn.functional` counterparts may be used. Examples being, resizing (nn.functional.interpolate),  average pooling (nn.functional.AvgPool2d) and activation functions.\n",
        "\n",
        "To import:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yl1Flqxz-FN9"
      },
      "source": [
        "import torch.nn.functional as F #contains some useful functions like activation functions & convolution operations you can use"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cLIjTzw-H7a"
      },
      "source": [
        "For more details see https://blog.paperspace.com/pytorch-101-advanced/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hideCode": false,
        "hidePrompt": false,
        "id": "XviDIqiIyY21"
      },
      "source": [
        "## 5.  Data Loading\n",
        "\n",
        "In Deep Learning, the data must be collected and prepared into batches before being fed into the neural network for training. In many cases, our medical imaging data is too large to be all loaded into memory at once. We may also want to transform (augment) our data either as a pre-processing step or to simulate the creation of bigger data sets. Typically we want to randomly shuffle our data during training such that our network does not always see data in the same order. Pytorch streamlines this process through the provision of two classes: *DataSet*, and accompanying iterator *DataLoader*.\n",
        "\n",
        "For common datasets such as MNIST and CIFAR10 Pytorch provides default `DataSets` https://pytorch.org/docs/stable/torchvision/datasets.html. However, for more bespoke applications it is necessary to create tailored `DataSet` classes which inherit from the base class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hideCode": false,
        "hidePrompt": false,
        "id": "WexyeLDLyY21"
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JD4KqrZUyY23"
      },
      "source": [
        "### 5.1 The Dataset and DataLoader Class\n",
        "\n",
        "Let's look at the basic structure of the `Dataset` class (https://github.com/pytorch/pytorch/blob/master/torch/utils/data/dataset.py) and discuss some of it's optional features. \n",
        "\n",
        "`class Dataset(object):  \n",
        "    \"\"\"An abstract class representing a :class:Dataset.\n",
        "    All datasets that represent a map from keys to data samples should subclass\n",
        "    it. All subclasses should overwrite :meth:__getitem__, supporting fetching a\n",
        "    data sample for a given key. Subclasses could also optionally overwrite\n",
        "    :meth:__len__/, which is expected to return the size of the dataset by many\n",
        "    :class:~torch.utils.data.Sampler implementations and the default options\n",
        "    of :class:~torch.utils.data.DataLoader.\n",
        "    .. note::\n",
        "      :class:~torch.utils.data.DataLoader by default constructs a index\n",
        "      sampler that yields integral indices.  To make it work with a map-style\n",
        "      dataset with non-integral indices/keys, a custom sampler must be provided.\n",
        "    \"\"\" \n",
        "    def __getitem__(self, index):\n",
        "        raise NotImplementedError\n",
        "    def __add__(self, other):\n",
        "        return ConcatDataset([self, other])`\n",
        "\n",
        "What this states is that any class that inherits from the baseclass must override the following methods:\n",
        "\n",
        "- `__len__` so that len(dataset) returns the size of the dataset.\n",
        "- `__getitem__` which returns a sample from the dataset given an index. For supervised learning from images this requires it to return both an example image and its label.\n",
        "\n",
        "In addition to this it is common to pass a transform argument to the `DataSet` class which will support augmentation of the data. After that you have great freedom as to the actual structure and ordering of the code in the class. \n",
        "\n",
        "The `DataLoader` is an iterator class, which uses the `__getitem__` and `__len__` functions to collate data into batches and sample at random (`shuffle`) from the data referenced by the `Dataset` class. It also supports loading and processing the data in parallel (with the number of parallel processes determined by parameter `num_workers`. **Generally shuffling the order of the data is very important** as, in this way, the batches between epochs will not look alike, improving generalisation.\n",
        "\n",
        "The generic form of a call to `DataLoader` is \n",
        "\n",
        "`dataloader = DataLoader(transformed_dataset, batch_size=4,\n",
        "                        shuffle=True, num_workers=4)`\n",
        "                        \n",
        "Unlike the `Dataset` class this is unlikely to need overloading.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hideCode": false,
        "hidePrompt": false,
        "id": "iA18GBbIyY24"
      },
      "source": [
        "### 5.2 Loading MNIST from torchvision\n",
        "\n",
        "Let's start by looking at how to use custom PyTorch datasets available through `torchvision.`\n",
        "\n",
        "The torchvision package consists of popular datasets, model architectures, and common image transformations for performing computer vision tasks.\n",
        "\n",
        "Let us use it to load the MNIST data set. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hideCode": false,
        "hidePrompt": false,
        "id": "LANtNlHiyY24"
      },
      "source": [
        "from torchvision import datasets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hideCode": false,
        "hidePrompt": false,
        "id": "85dRT_f4yY26"
      },
      "source": [
        "MNIST is found under datasets.MNIST. The class supports direct download of the data from the internet as indicated by the `download` argument. It is necessary to define a target directory for the download as `root`. Data is also already separated into `train` and `test` subsets. For further help understanding the class datasets.MNIST, use $\\text{datasets.MNIST.__doc __}$ to view the documentation or view https://pytorch.org/docs/stable/torchvision/datasets.html#mnist."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hideCode": false,
        "hidePrompt": false,
        "id": "LBiVjffwyY27"
      },
      "source": [
        "print(datasets.MNIST.__doc__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hideCode": false,
        "hidePrompt": false,
        "id": "8HXq6BzbyY29"
      },
      "source": [
        "There are many potential transformations that are supported through `torchvision` and can be performed to the image (such as rotations, crops, flips, etc). The use of these is controlled by the `transform` argument of the `Dataset` class. Here, however, we will only apply a transformation to turn the PIL format image into a torch tensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hideCode": false,
        "hidePrompt": false,
        "id": "5to9-8E9yY2-"
      },
      "source": [
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "mnist_train_dataset = datasets.MNIST(root = 'mnist_data/train', download= True, train = True,\n",
        "                                     transform = transforms.ToTensor())\n",
        "mnist_test_dataset = datasets.MNIST(root = 'mnist_data/test', download= True, train = False, \n",
        "                                    transform = transforms.ToTensor())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hideCode": false,
        "hidePrompt": false,
        "id": "WvoOz9DAyY2_"
      },
      "source": [
        "To explore the shape of the data set we must used the overloaded class function ```len()``` to determine the number of examples. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hideCode": false,
        "hidePrompt": false,
        "id": "LmYgIBn2yY3A"
      },
      "source": [
        "print(len(mnist_train_dataset))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hideCode": false,
        "hidePrompt": false,
        "id": "k7PhT46byY3B"
      },
      "source": [
        "In this case, as MNIST is an image classfication data set. Each individual item is a tuple, representing the data and its integer label i.e."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hideCode": false,
        "hidePrompt": false,
        "id": "qQ1-fijSyY3C"
      },
      "source": [
        "print(type(mnist_train_dataset[0]))\n",
        "ex_train_image, ex_train_label=mnist_train_dataset[0]\n",
        "                                                   \n",
        "print('Image shape',ex_train_image.shape,'label',ex_train_label,type(ex_train_label))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hideCode": false,
        "hidePrompt": false,
        "id": "2mnQTvVayY3D"
      },
      "source": [
        "We can visualise the data using matplotlibs `imshow` function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hideCode": false,
        "hidePrompt": false,
        "id": "glm9gW-wyY3E"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.imshow(ex_train_image[0,:,:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hideCode": false,
        "hidePrompt": false,
        "id": "jUv65h8FyY3G"
      },
      "source": [
        "Thus, we see that mnist_train_dataset contains 60k 28x28 images of hand-written numbers, with labels (the integer numbers from 0-9), in torch tensor format.\n",
        "\n",
        "To use this data for deep learning, we can then load both test and train sets onto dataloaders, which dispatch batches and shuffle the data for us as:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hideCode": false,
        "hidePrompt": false,
        "id": "axFqxTF-yY3H"
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(\n",
        "       mnist_train_dataset, batch_size= 128, shuffle = True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "       mnist_test_dataset, batch_size = 128, shuffle = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hideCode": false,
        "hidePrompt": false,
        "id": "kY0_F8bcyY3I"
      },
      "source": [
        "Shuffling is not required for test data.\n",
        "\n",
        "Now that we have our dataloaders, we can simply iterate through them with the inbuilt iter() function.\n",
        "<br>\n",
        "To view just one batch instead of the entire data, we use apply the next() function on the iterator:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hideCode": false,
        "hidePrompt": false,
        "id": "GHopwljRyY3J"
      },
      "source": [
        "im_batch, lab_batch=next(iter(train_loader)) # view one batch\n",
        "\n",
        "print(len(im_batch),im_batch[0].shape,lab_batch[0])\n",
        "plt.imshow(im_batch[0,0,:,:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hideCode": false,
        "hidePrompt": false,
        "id": "EBzRcrkxyY3L"
      },
      "source": [
        "This returns one batch -  a tuple of images and labels. By looking at the image batch we can see N (first column) is 128 - the size of the batch. Image dminesions are $1 \\times 28 \\times 28$ as before."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hideCode": false,
        "hidePrompt": false,
        "id": "VXYh0OlsyY3L"
      },
      "source": [
        "### 5.3 Loading custom data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hideCode": false,
        "hidePrompt": false,
        "id": "unCa_UuyyY3M"
      },
      "source": [
        "The process for loading a customised dataset is not so far from the process above, except that we need to define our own dataset class. \n",
        "\n",
        "\n",
        "This class only needs two defined functions. One that provides the `len()` of the dataset, the other called `getitem` that outputs one data pair given an index.\n",
        "\n",
        "*How* this is done is up to you. The method we go over is only a suggestion. However you choose to do it, `getitem` must, given an index, output the data and its appropriate label, corresponding to that index. This is because the DataLoader class will call this function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hideCode": false,
        "hidePrompt": false,
        "id": "CTbXm7NUyY3M"
      },
      "source": [
        "In this example, we will use an example of image segmentation from computer vision, with a dataset which contains photos of scences accompanied by their semantic segmentations. Thus the label is now an image of size equal to that of the data.\n",
        "\n",
        "\n",
        "We will read the images and segmentation masks from the ```sample_dataset_tutorial``` folder downloaded with your tutorial. Since they are .png files, we will need to import the imageio module to allow us to load them from this format. We will also need to import os to access the folders and directories in the computer via python."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hideCode": false,
        "hidePrompt": false,
        "id": "CT5GX3jhyY3M"
      },
      "source": [
        "import imageio\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hideCode": false,
        "hidePrompt": false,
        "id": "7gMXsnfcyY3O"
      },
      "source": [
        "class OurCustomDataSet(torch.utils.data.Dataset): #we create a class that inherits the torch Dataset abstract class \n",
        "    \n",
        "    def __init__(self, data_folder_location): # initialise the class based on the folder containing the data\n",
        "        \n",
        "        \"\"\"\n",
        "        \n",
        "        \n",
        "        First look at the folder containing the data. It is structured in two folders.\n",
        "        There are images in an 'images' folder, and masks in a 'segmentations' folder. \n",
        "        We need to match these up together and correctly.\n",
        "        \n",
        "        \n",
        "        \n",
        "        First we define the root folder and extract the images and segmentations subfolders \n",
        "        containing the data (images) and the labels (segmentations).\n",
        "        \n",
        "        \n",
        "        \n",
        "        \"\"\"\n",
        "        \n",
        "        self.data_folder_location = data_folder_location\n",
        "        \n",
        "        self.images_folder = data_folder_location + '/images'\n",
        "        \n",
        "        self.labels_folder = data_folder_location + '/segmentations'\n",
        "        \n",
        "        \"\"\"\n",
        "        \n",
        "        Now we use os.listdir() to get a list of the files within the subfolders. \n",
        "        \n",
        "        We sort both these lists to make sure that the image files' titles and \n",
        "        the segmentation files' titles match. \n",
        "        \n",
        "        They are titled in such a way to allow this to work by simply sorting. \n",
        "        \n",
        "        (Other data might require more a more complex matching process.\n",
        "        e.g. you might construct a dictionary matching image title to mask title)\n",
        "        \n",
        "        \"\"\"\n",
        "        \n",
        "        \n",
        "        \n",
        "        self.images_list_sorted = os.listdir(self.images_folder)\n",
        "        self.images_list_sorted.sort()\n",
        "        \n",
        "        self.labels_list_sorted = os.listdir(self.labels_folder)\n",
        "        self.labels_list_sorted.sort()\n",
        "\n",
        "        \n",
        "        return\n",
        "    \n",
        "    def __len__(self):\n",
        "        # this returns the length of the dataset. It is usually simple to code\n",
        "        \n",
        "        return len(os.listdir(self.images_folder))\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        \n",
        "        \"\"\"\n",
        "        \n",
        "        getitem should pull the idx'th image and its associated segmentation and output them together as a sample\n",
        "        \n",
        "        we begin by indexing the list of image and label //titles// \n",
        "        \n",
        "        \"\"\"\n",
        "        \n",
        "        image_name = self.images_list_sorted[idx] # this is the idx'th image\n",
        "        \n",
        "        label_name = self.labels_list_sorted[idx] # this is the idx'th segmentation  # THEY SHOULD MATCH\n",
        "        \n",
        "        \"\"\"\n",
        "        \n",
        "        Now we have to load the png files given these titles. \n",
        "        \n",
        "        We first find their exact locations and then load them using imageio\n",
        "        \n",
        "        \"\"\"\n",
        "        \n",
        "        full_image_location = str(self.images_folder)+'/' + str(image_name)\n",
        "        \n",
        "        full_label_location = str(self.labels_folder) + '/' + str(label_name)\n",
        "        \n",
        "        image = imageio.imread(full_image_location)\n",
        "        \n",
        "        label = imageio.imread(full_label_location)\n",
        "        \n",
        "        \"\"\"\n",
        "        \n",
        "        Before we output, they are currently in .png format. So we need to turn them into torch Tensors\n",
        "        \n",
        "        \"\"\"\n",
        "        \n",
        "        image = transforms.ToTensor()(image)\n",
        "        label = transforms.ToTensor()(label)\n",
        "             \n",
        "        sample = image, label\n",
        "        \n",
        "        return sample"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hideCode": false,
        "hidePrompt": false,
        "id": "aSIEgMuwyY3Q"
      },
      "source": [
        "Now to try out our custom dataset. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0gyeu5sK9M2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hideCode": false,
        "hidePrompt": false,
        "id": "oZUoCLLGyY3S"
      },
      "source": [
        "directory = '/content/drive/My Drive/Colab Notebooks/Colab_Data/week1-Data/sample_dataset_tutorial/'  # we define the directory of the data\n",
        "\n",
        "ds = OurCustomDataSet(directory) # then we create the dataset "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hideCode": false,
        "hidePrompt": false,
        "id": "tcbde6e8yY3V"
      },
      "source": [
        "ds.__len__() # check if the length is correct. We can see from the folders there are 18 items in total\n",
        "             # we should get the same result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hideCode": false,
        "hidePrompt": false,
        "id": "agTLoypKyY3X"
      },
      "source": [
        "# Now lets try to pull out a sample. Lets try the first one.\n",
        "\n",
        "example_im,ex_label=ds.__getitem__(0)\n",
        "print(type(example_im),example_im.shape,ex_label.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hideCode": false,
        "hidePrompt": false,
        "id": "5MFZow02yY3Y"
      },
      "source": [
        "It worked! It returned two torch tensors, one labeled 'image' the other labeled 'label'.\n",
        "\n",
        "\n",
        "If you are wish to be extra sure that they match, we can plot them "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hideCode": false,
        "hidePrompt": false,
        "id": "LE7jwB3UyY3Z"
      },
      "source": [
        "im, lab = OurCustomDataSet(directory).__getitem__(14) # im , lab are our image and label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hideCode": false,
        "hidePrompt": false,
        "id": "BQ93Y8RCyY3a"
      },
      "source": [
        "transforms.ToPILImage()(im) # quickly converting back to PIL image to view it"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hideCode": false,
        "hidePrompt": false,
        "id": "co4m8JPVyY3d"
      },
      "source": [
        "transforms.ToPILImage()(lab)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hideCode": false,
        "hidePrompt": false,
        "id": "987Ella6yY3g"
      },
      "source": [
        "We are done! At this point we simply need to load our dataset into the dataloader as usual and the dataloader will provide batches for our deep learning algorithm."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hideCode": false,
        "hidePrompt": false,
        "id": "pstESzppyY3g"
      },
      "source": [
        "loaded_data = DataLoader(ds, batch_size = 2, shuffle = False)\n",
        "\n",
        "im_batch, lab_batch = next(iter(loaded_data)) # get a batch\n",
        "print(im_batch.shape) # we get [2,3,1500,200] which we expect since the \n",
        "                      # images are [3 x 1500 x 2500] and the batch size is 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hideCode": false,
        "hidePrompt": false,
        "id": "bOal7b4pyY3i"
      },
      "source": [
        "### Exercise 3: Create a custom data Loader for medical data\n",
        "\n",
        "In this exercise we will create a custom data loader to load medical imaging data, and medical segmentations or phenotypic label data.\n",
        "\n",
        "The data that we will use can be found in folder `dHCP_brain_data` (downloadable from Keats); this contains: 3D brain volumes, tissue segmentations and a pickled dataframe (`dHCP_demographics.pkl`) containing phenotypes including the infants age at birth ('birth_ga'), age at scan ('scan_ga') and gender ('gender'). Individual images can be identified by their subject 'id' (starting 'CC00') and the `session` of the scan (e.g. '7201'). This is reflected in filenames starting (for example) `sub-CC00050XX01_ses-7201` with files:\n",
        "1. sub-CC00050XX01_ses-7201_T2w_restore_brain.nii.gz a T2-weighted structural image of each neonates brain\n",
        "2. sub-CC00050XX01_ses-7201_drawem_tissue_labels.nii.gz a semantic segmentation of tissues in the brain, including labels for cortical and subcortical grey matter, white matter and cerebral spinal fluid (CSF). For the full list of labels see https://github.com/MIRTK/DrawEM/blob/master/label_names/tissue_labels_LUT_ITKSNAP.txt\n",
        "\n",
        "For context, the image files look as \n",
        "\n",
        "<img src=\"https://drive.google.com/uc?id=1bJOvNcnHsnsxoextjzClOQdGuYJbNc9c\" alt=\"Drawing\" style=\"width: 800px;\"/>\n",
        "\n",
        "And can be viewed individually using 3D nifti image viewers such as [FSLeyes](https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/FSLeyes) or the Human Connectome Projects image viewer (called workbench) with application [wb_view](https://www.humanconnectome.org/software/connectome-workbench). \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hideCode": false,
        "hidePrompt": false,
        "id": "eHsrTPb6yY3i"
      },
      "source": [
        "#### Task 3.1 Create a data loader for brain images and their segmentations\n",
        "\n",
        "In the first task, as for the computer vision example we will create a dataloader to load brain images and their segmentations.\n",
        "\n",
        "First we need a module that will load medical image volumes (here niftii images .nii.gz). There are several options including `SimpleITK`. Here, we use `nibabel`.\n",
        "\n",
        "**To do** change the direcory path to correspond to where you've put the data on your own drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XW4-AG2yY3i"
      },
      "source": [
        "import nibabel # nibabel is a python module for reading different types of medical image format\n",
        "import os # os is a python standard module which allows manipulation of file paths (here combining directory paths with file paths)\n",
        "\n",
        "# STUDENTS - specify path to data folder relative to your drive ###\n",
        "directory = '/content/drive/My Drive/Colab Notebooks/Colab_Data/week1-Data/dHCP_brain_data/'  # we define the directory of the data\n",
        "\n",
        "\n",
        "image_file=nibabel.load(os.path.join(directory,'sub-CC00050XX01_ses-7201_T2w_restore_brain.nii.gz')) # see here use of os.path.join to create the final path\n",
        "segmentation_file=nibabel.load(os.path.join(directory,'sub-CC00050XX01_ses-7201_drawem_tissue_labels.nii.gz'))\n",
        "\n",
        "img=image_file.get_fdata().astype(np.float)\n",
        "seg=segmentation_file.get_fdata().astype(np.int32)\n",
        "print(img.shape,seg.shape)\n",
        "print(type(img),type(seg))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3LPSgiNSyY3k"
      },
      "source": [
        "As we can see, loading data in this way returns a numpy array. Thus converting to a torch tensor is straightforward as"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSYuLpaIyY3k"
      },
      "source": [
        "img_tensor = torch.from_numpy(img).to(torch.float)\n",
        "seg_tensor=torch.from_numpy(seg).to(torch.float)\n",
        "print(img_tensor.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4RzYEVsYyY3m"
      },
      "source": [
        "Using `imshow` to view one central slice of the image and it's segmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "796_gVLbyY3m"
      },
      "source": [
        "print(img_tensor.shape)\n",
        "fig, ax = plt.subplots(ncols=2, sharex=True, sharey=True,\n",
        "                       figsize=(8, 4))\n",
        "ax[0].imshow(img_tensor[:,:,120], cmap=plt.cm.gray)\n",
        "ax[0].set_title('T2 image - axial slice')\n",
        "ax[1].imshow(seg_tensor[:,:,120], cmap=plt.cm.Dark2)\n",
        "ax[1].set_title('Tissue segmentation')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GksJ8D_GyY3n"
      },
      "source": [
        "However, as we are dealing with 3D volumes we need to reshape our images into the form, which they will expected by Pytorch in order to perform convolutions. This is: $C\\times D \\times H \\times W $, where $C$=channels (otherwise known as features, here 1 - we only have one structural image per example), $D$=depth, $H$=height and $W$ = width (https://pytorch.org/docs/master/nn.html#torch.nn.Conv3d). \n",
        "\n",
        "Hence, we need to bring our re-order the spatial dimensions of our tensor, using Pytorch `permute`0, 1) to 1) put depth first."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mwS1NqIyY3o"
      },
      "source": [
        "img_tensor=img_tensor.permute(2,0,1)\n",
        "print(img_tensor.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJOWpeAByY3q"
      },
      "source": [
        "And 2) add a fourth dimension for channels. This can be done using the PyTorch `unsqueeze` function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXB4nqlZyY3q"
      },
      "source": [
        "img_tensor=img_tensor.unsqueeze(0)\n",
        "print(img_tensor.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNE-UbWNyY3s"
      },
      "source": [
        "Now, we need a way of returning the paths of the data from an index. We could put images and segmentations into different folders (as above) and sort but this could feasibly lead to difficult to track down bugs. Let us instead use the project dataframe instead, using pandas:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0M-c7x9RyY3s"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "meta_path=os.path.join(directory,'dHCP_demographics.pkl')\n",
        "meta=pd.read_pickle(meta_path)\n",
        "print(meta)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wv_dHpkkyY3v"
      },
      "source": [
        "Each image file can thus be defined through:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9amIbX3yY3v"
      },
      "source": [
        "meta_sample=meta.iloc[0]\n",
        "img_path=os.path.join(directory,'sub-' + str(meta_sample['id']) +'_ses-' + str(meta_sample['session']) +'_T2w_restore_brain.nii.gz')\n",
        "\n",
        "img_sample=nibabel.load(img_path)\n",
        "\n",
        "print(img_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ioo1b3ISyY3x"
      },
      "source": [
        "**STUDENTS TASK (EX 3.1)** Putting this all together, use these functions to create your own data loader for pairs of brain imaging data and clinical segmentations in the following steps\n",
        "\n",
        "1.  complete the class constructor - used to initialise class variables: folder (path to data folder), meta (the dataframe) and transform\n",
        "2. Complete the overloaded __len(self)__ class, to return the number of data examples\n",
        "In `__getitem__`:\n",
        "3.  return the paths to the image and the segmentation file\n",
        "4. load the images\n",
        "5. Convert to tensors and reshape to expected dimensions $C\\times D \\times H \\times W $ (as described above)\n",
        "\n",
        "**hint** consider also looking to https://pytorch.org/tutorials/beginner/data_loading_tutorial.html for guidance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hideCode": false,
        "hidePrompt": false,
        "id": "4cDGORScyY3x"
      },
      "source": [
        "# students create own data set\n",
        "\n",
        "#we create a class that inherits the torch Dataset abstract class \n",
        "class BrainSegmentationDataset(torch.utils.data.Dataset): \n",
        "    \n",
        "    # initialise the class based on the folder containing the data and the project dataframe\n",
        "    def __init__(self, folder='', meta='',transform=None): \n",
        "        \n",
        "        # STUDENTS CODE - replace Nones with correct code #\n",
        "       # 2.1.1 initialise the paths to the data folder, the data frame and define the transform operations\n",
        "        self.folder = None\n",
        "        self.meta = None\n",
        "        self.transform=transform\n",
        "        \n",
        "    \n",
        "    def __len__(self):\n",
        "        # STUDENTS CODE - replace Nones with correct code #\n",
        "         # 2.1.2 return the number of examples in the dataset\n",
        "        return None\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        \n",
        "        # STUDENTS CODE - replace Nones with correct code #\n",
        "        # 2.1.3 return the paths to the image and the segmentation file \n",
        "        meta_sample=self.meta.iloc[idx] # this will return the idx-th row from the dataframe\n",
        "        image_name = None  # use this to sample idx'th image (create image path using meta_sample)  \n",
        "        label_name = None # do the same for the idx'th segmentation  # THEY SHOULD MATCH\n",
        "        \n",
        "        # 2.1.4 load images \n",
        "        image=None\n",
        "        label=None\n",
        "        \n",
        "        # 2.1.5 Convert to tensors and \n",
        "        img_tensor = None\n",
        "        seg_tensor=None\n",
        "        \n",
        "        # 2.1.5 reshape to expected dimensions using permute and unsqueeze (you can do this in one or two steps per tensor)\n",
        "        img_tensor=None\n",
        "        seg_tensor=None\n",
        "        \n",
        "        # convert to  tuple and return\n",
        "        sample = img_tensor, seg_tensor\n",
        "\n",
        "        if self.transform:\n",
        "            sample = self.transform(sample)\n",
        "            \n",
        "        return sample"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EB5ayqJmyY30"
      },
      "source": [
        "## Ex 3.2 Try out your custom data set and try out the DataLoader class\n",
        "\n",
        "**To Do** \n",
        "\n",
        "1. Instantiate (create) an instance of your data set by calling the BrainSegmentationDataset class constructor\n",
        "2. check that the length is correct\n",
        "3. return index 0 from getitem, \n",
        "4. plot the 120th axial slice of the returned img and segmentation. Be sure your segmentation matches your image  **Hint** remember that we have permuted the order of our slices and added a dimension for channels\n",
        "5. Create a class iterator using DataLoader and create a batch of size 3, print the shape of the output\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNIZrlpYyY31"
      },
      "source": [
        "# STUDENTS CODE - replace Nones with correct code #\n",
        "\n",
        "#2.2.1 Create an instance of the BrainSegmentationDataset class by calling the constructor\n",
        "ds = None # then we create the dataset \n",
        "\n",
        "#2.2.2 check that the length is correct\n",
        "None\n",
        "\n",
        "#2.2.3 return index 0 from getitem\n",
        "example_im,ex_label=None\n",
        "print(type(example_im),example_im.shape,ex_label.shape)\n",
        "\n",
        "#2.2.4 plot the 120th axial slice by changing Nones for correct slice of image\n",
        "fig, ax = plt.subplots(ncols=2, sharex=True, sharey=True,\n",
        "                       figsize=(8, 4))\n",
        "ax[0].imshow(None, cmap=plt.cm.gray)\n",
        "ax[0].set_title('T2 image - axial slice')\n",
        "ax[1].imshow(None, cmap=plt.cm.Dark2)\n",
        "ax[1].set_title('Tissue segmentation')\n",
        "\n",
        "#2.2.5 Create a class iterator using DataLoader and create a batch of size 3\n",
        "loaded_data = None\n",
        "\n",
        "im_batch, lab_batch = next(iter(loaded_data)) # get a batch\n",
        "print('batch shape', im_batch.shape) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGWATNUh9vWd"
      },
      "source": [
        "# 6. Implementing Neural Networks with Pytorch \n",
        "\n",
        "We are now in a position to start building simple networks. To do this in Pytorch we must always define a specific class to represent our network. We can do this in two steps, by inheriting from `nn.Module`. Let's start by importing all the modules we will need:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRcA1TVG_ZMC"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F #contains some useful functions like activation functions & convolution operations you can use\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OlTrjd_iKuK1"
      },
      "source": [
        "## 6.1 GPU or CPU?\n",
        "\n",
        "Before we can even begin, we need to know whether we are using a GPU or a CPU. If its the former, the model and all the data should be uploaded into the GPU. Fortunately, we can define a variable \"device\" that will either be cpu or gpu depending on availability, and load the data automatically on the correct 'device'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yswtWq08KuyJ"
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "    \n",
        "print(device) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4NDx36p_bKb"
      },
      "source": [
        "We see that if cuda is available our model will be run on a GPU, otherwise the model will need to run on CPU.\n",
        "\n",
        "## 6.2 Defining a network class.\n",
        "\n",
        "A PyTorch network class is then defined from a minimum of two functions:\n",
        "\n",
        "1. The first part is creation of the constructor `__init__` in which you must define all parameters and layers that you will use. **Note**, you must always define the super() function to initialize and start the parent class\n",
        "2. The second part is to define the forward pass through the function `forward(self,x)` which puts these layers together to calculates the output.\n",
        "\n",
        "For example, here is the most simple network possible - a linear regression model - it has a single `nn.Linear` layer, which takes an input of size [1] and outputs also size [1]."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3TMsfc1T-f4e"
      },
      "source": [
        "class Model(nn.Module):\n",
        "   def __init__(self):\n",
        "       super(Model, self).__init__()\n",
        "       self.layer = torch.nn.Linear(1, 1)\n",
        "\n",
        "   def forward(self, x):\n",
        "       x = self.layer(x)      \n",
        "       return x\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqKCGP63BAUi"
      },
      "source": [
        "While we explicitly define our forward pass, backpropagation is automatically defined by autograd and this does not need to be coded up.\n",
        "\n",
        "Once complete, you can then create an instance of the class using net = Model()."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMI6dPVUBOUZ"
      },
      "source": [
        "net = Model()\n",
        "print(net)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GtNgVV98BCZV"
      },
      "source": [
        "## 6.3 Training\n",
        "\n",
        "Now we have defined and initialised our network, we must perform training to optimise the parameters (or weights of the network). For this we must choose a loss function and optimiser:\n",
        "\n",
        "### 6.3.1 Loss Function\n",
        "The loss function is used to measure how well the prediction model is able to predict the expected results. PyTorch already has many standard loss functions in the torch.nn module. For example, you can use the Cross-Entropy Loss to solve a multi-class classification problem, or a mean squared error (MSE) loss for regression. \n",
        "\n",
        "For example, to define the loss function and compute the losses:\n",
        "\n",
        "```python\n",
        "# First define the loss function e.g\n",
        "# multiclass cross entropy loss\n",
        "loss_CE = nn.CrossEntropyLoss()\n",
        "# mean square error loss\n",
        "loss_MSE = nn.MSELoss()\n",
        "\n",
        "#Then to call the loss function during training \n",
        "loss = loss_CE(prediction, target)\n",
        "```\n",
        "\n",
        "### 6.3.2 Optimizer\n",
        "There are many optmizers available in pytorch - see https://pytorch.org/docs/stable/optim.html for full list and further examples. We will discuss loss functions and optimisers in more detail in week 2.\n",
        "\n",
        "You define an optmizer in the following way:\n",
        "\n",
        "```python\n",
        "# The Stochastic gradient descent optimiser (with momentum set to true)\n",
        "optim = torch.optim.SGD(net.parameters(), lr = 0.01, momentum=0.9)\n",
        "```\n",
        "\n",
        "### 6.3.3. Forward pass\n",
        "\n",
        "When performing a forward pass you never explicitly call the `forward` function  rather the inherited torch.nn.Module handles this behind the scenes. For more details see: https://discuss.pytorch.org/t/predict-output-by-model-does-not-need-call-forward/1489\n",
        "\n",
        "Thus the entire forward pass reduces to two lines:\n",
        "\n",
        "```\n",
        "# make prediction with forward pass\n",
        "prediction = net(inputs) \n",
        "\n",
        "# Compute loss by calling the loss function \n",
        " loss = loss_func(prediction, outputs) \n",
        "\n",
        "```\n",
        "\n",
        "### 6.3.4 Backprop and clearing gradients\n",
        "To perform the backpropagation, you call the loss.backward(), followed by optim.step(). **You should clear gradients before every training iteration to ensure there's no gradients remaining**. This is to avoid mixing up gradients between minibatches. More specifically however, it is an sideeffect of the fact that PyTorch implements dynamic computation graphs as opposed to static ones (like tensorflow). In addition, the fact that the backward() function in Pytorch accumulates gradients is useful for Recurrent Neural Networks and complex networks with multiple different parts.\n",
        "\n",
        "```python\n",
        "net.zero_grad() # to clear the existing gradient - this should be done prior to a training pass\n",
        "optim.zero_grad() # to clear gradient in optimizer - this is equivalent to net.zero_grad(). \n",
        "loss.backward() # to perform backpropragation - accumulates the gradient (by addition) for each parameter\n",
        "optim.step() # optimizer.step is performs a parameter update based on the current gradient (stored in .grad attribute of a parameter) and the update rule. \n",
        "```\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCVJR72iSjo7"
      },
      "source": [
        "## 6.4 Example - training a linear regression model\n",
        "\n",
        "### 6.4.1 First simulate some data \n",
        "\n",
        "We can create simulated data to test our simple regression network. The aim is to use our neural network to estimate/ make predictions. \n",
        "\n",
        "We use the following function to randomly generate 100 data points:\n",
        "\n",
        "$Y = \\cos(x) \\times x^3 + 4x + 0.6 \\times rand()$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56DIzmPqDm_i"
      },
      "source": [
        "# Visualize our data\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "\n",
        "x = np.random.rand(100)\n",
        "y = np.cos(x) * np.power(x,3) + 4*x + np.random.rand(100)*0.6\n",
        "\n",
        "plt.scatter(x, y)\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gL-wR2opD0YY"
      },
      "source": [
        "Since we're using pytorch, we need to convert our numpy array to a pytorch tensor. The size of the input will be [100, 1], where 100 is the batch size, and 1 is the size of the input (as previously defined in our neural network)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9Hlqh57D7M8"
      },
      "source": [
        "# convert numpy array to tensor in shape of input size\n",
        "x = torch.from_numpy(x.reshape(-1,1)).float()\n",
        "y = torch.from_numpy(y.reshape(-1,1)).float()\n",
        "print(x.size(), y.size())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "853FW_kvEIg-"
      },
      "source": [
        "Now, given the network class we defined above, to train we must go through the following steps (any network we train we follow the same broad structure)\n",
        "\n",
        "### 6.4.2 Define the optimizer and loss function\n",
        "\n",
        "We first define our optimizer and loss function. Here, we will use stochastic gradient descent (with momentum) as the optimiser. Since we are performing regression, the loss function we chose is Mean Squared Error, or l2 loss. Another common loss function for regression is the Mean Absolute Error, or l1 loss.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zq-GFw7tEPma"
      },
      "source": [
        "# Define Optimizer and Loss Function\n",
        "#------------------------------------------------------task 1----------------------------------------------------------------\n",
        "# Task 1: change optimizer here\n",
        "optimizer = torch.optim.SGD(net.parameters(), lr=0.2)\n",
        "# Task 1: change loss function here\n",
        "loss_func = torch.nn.MSELoss()\n",
        "#----------------------------------------------------------------------------------------------------------------------------\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3bPA472EOML"
      },
      "source": [
        "### 6.4.3 Implement a training loop\n",
        "\n",
        "Then we construct a training loop with the following steps \n",
        "\n",
        "1. Clear gradients!!\n",
        "2. Pass data through the network (forward pass)\n",
        "3. Compute loss\n",
        "4. Compute Backward pass \n",
        "5. update network parameters\n",
        "\n",
        "During training we iterate through our data. Here we use number of epochs = 200, but the optimal number largely depends on the dataset and the task.\n",
        "\n",
        "See how these 5 steps are called for a basic network below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ieTnw73XEd0x"
      },
      "source": [
        "inputs = x \n",
        "outputs = y \n",
        "epochs = 200\n",
        "for i in range(epochs):\n",
        "    \n",
        "    # 1. clear gradients - here we could interchangibly use net.zero_grad()\n",
        "    optimizer.zero_grad() \n",
        "    \n",
        "    # 2. pass data through network - note how you never explicitely call the forward pass\n",
        "    prediction = net(inputs) \n",
        "    # 3. Compute loss by calling the loss function defined above\n",
        "    loss = loss_func(prediction, outputs) \n",
        "    # 4. accumulate gradients by calling the backwards pass \n",
        "    loss.backward()       \n",
        "    # 5. update network parameters\n",
        "    optimizer.step() \n",
        "\n",
        "    # Display results\n",
        "    if i % 10 == 0:\n",
        "        # note how we need to tranform data back to numpy\n",
        "        plt.cla()\n",
        "        plt.scatter(x.data.numpy(), y.data.numpy())\n",
        "        plt.plot(x.data.numpy(), prediction.data.numpy(), 'r-', lw=2)\n",
        "        plt.text(0.5, 0, 'Loss=%.4f' % loss.data.numpy(), fontdict={'size': 10, 'color':  'red'})\n",
        "        plt.pause(0.1)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nPg1yD1FCcjo"
      },
      "source": [
        "Carefully read through this code and check that you understand what all the steps are doing. You are going to need to replicate this basic structure going forward.\n",
        "\n",
        "### 6.4.4 Result\n",
        "\n",
        "We have now set up and performed simple regression with a neural network. You can see the results above, how in every iteration the red line (the prediction) updates, and moves closer to fit the data.\n",
        "\n",
        "**You can perform regression with any neural network- the important step to remember is that your final layer should be of output size [1], and the loss function you use is suitable for regression - e.g. mean squared error, absolute squared error**\n",
        "\n",
        "### 6.4.5 Task\n",
        "\n",
        "1. change the loss function to Mean Absolute Error (l1 loss) - which loss function work better?\n",
        "2. change the optimiser?\n",
        "\n",
        "## Exercise 4 - MNIST image classification using a fully connected (MLP) network\n",
        "\n",
        "Now we have demonstrated the common structure of PyTorch networks and training loops we ask you to complete generation of a fully connected (MLP) network class for classification of MNIST images into 10 classes (one for each digit).\n",
        "\n",
        "We suggest the network consists of 2 fully connected hidden layers and an output layer with 10 neurons with softmax activation (to estimate the probabilkties of each class). \n",
        "\n",
        "As discussed in the video lectures, each hidden layer corresponds to a linear transform (coded as a `nn.linear` layer) followed by a non-linear activation function. We will use ReLu activations for hidden layers  **Each hidden layer should have 50 neurons**. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8lQh4n8Ql-Z"
      },
      "source": [
        "\n",
        "\n",
        "**To do 4.1 : Create the dataloaders**\n",
        "\n",
        "Run this code to regenerate the MNIST train and test dataloaders with batch size 128"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTH5g330M3h4"
      },
      "source": [
        "from torchvision import datasets, models, transforms\n",
        "\n",
        "mnist_train_dataset = datasets.MNIST(root = 'mnist_data/train', download= True, train = True, transform = transforms.ToTensor())\n",
        "mnist_test_dataset = datasets.MNIST(root = 'mnist_data/test', download= True, train = False, transform = transforms.ToTensor())\n",
        "\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "       mnist_train_dataset, batch_size= 128, shuffle = True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "       mnist_test_dataset, batch_size = 128, shuffle = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZvDDZGPNRok"
      },
      "source": [
        "\n",
        "**To DO 4.2  sketch the design of your network**\n",
        "\n",
        "Remember the definition of fully connected networks is that there is a connection between every single neuron. If we consider our input data as the input layer then each feature in the input must connect to each neuron in the first hidden layer. To make this work for images we must first stretch each $28 \\times 28$ MNIST image into a single vector (see line 18). This gives us $28 \\times 28$ input features. \n",
        " - If our hidden layer each have 50 neurons, what should be the sizes of their weights matrices?\n",
        " - MNIST has 10 classes, thus how many neurons do we need in our output layer and what will be the dimensions of its weight matrix?\n",
        "\n",
        "**To Do 4.3 - complete the `__init__` constructor of a MNIST_MLP class**\n",
        "\n",
        "1. Use `super` to access functions from the super class\n",
        "2. Use `nn.linear(in_features,out_features)` ( see https://pytorch.org/docs/stable/nn.html#torch.nn.Linear) to define the first hidden layer. Remember `in_features` will be the number on input neurons (features of the input data) and `out_features` is the number of neurons in the hidden layer. Here, we have created the linear layer for you, you just need to replace in_features and out_features with the exact dimensions of the layer\n",
        "3. Then create a second `nn.linear`  hidden layer. Given your network design how many input and output neurons should it have?\n",
        "4. Use `nn.linear` to define the output layer. Given your network design how many input and output neurons should it have?\n",
        "\n",
        "We define the forward function for you. This determines how the layers (defined in `__init__` are pieced together. You can see how line by line the output of each layer is fed in as the input to the next. Here Relu's are applied in the forward function as they learn no parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwvO0iV-F-ac"
      },
      "source": [
        "class MNIST_MLP(nn.Module):\n",
        "    \n",
        "    def __init__(self):\n",
        "        # Task 4.2.1 call super to access functions from the inherited class\n",
        "        None\n",
        "        \n",
        "        # Task 4.2.2 define the first hidden layer using nn.linear(in_feataures,out_features)\n",
        "        # You need to replace `in_features` with the number of pixels in each image (total number of features)\n",
        "        # You need to replace `out_features` with number of hidden neurons in the first layer (defined above)\n",
        "        self.fc1 =  nn.Linear(None, None) \n",
        "\n",
        "        # Task 4.2.3 Now repeat the process second hidden layer\n",
        "        self.fc2 =None\n",
        "        \n",
        "        # Task 4.2.4 Now repeat the process for the output layer - how many output neurons will you need for this \n",
        "        # multi-class problem?\n",
        "        self.fc3 = None\n",
        "        \n",
        "        # we define the output activation as softmax\n",
        "        self.softmax = nn.Softmax(dim = 1)\n",
        "        \n",
        "    def forward(self, x): \n",
        "        \n",
        "        # flattens the MNIST images to a 28 x 28 feature vector \n",
        "        #where 28 is the height and width dimensions of each image)\n",
        "        x = x.view(-1, 28*28) \n",
        "\n",
        "        # layer one combines the first linear activation layer self.fc1 with a relu activation\n",
        "        # as relu has no parameters it is common to define it in the forward function (instead of init) using the functional form F.relu\n",
        "        x = F.relu(self.fc1(x))\n",
        "        \n",
        "        # layer two combined the second linear activation layer with a second relu\n",
        "        x = F.relu(self.fc2(x))\n",
        "        \n",
        "        # we then call the output layer\n",
        "        x = self.fc3(x)  \n",
        "        \n",
        "        # and pass it through a softmax to turn the pr4edictions into class probabilities\n",
        "        x = self.softmax(x)\n",
        "        return x\n",
        "\n",
        "# After we have defined our model we load it onto our device\n",
        "model = MNIST_MLP().to(device) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NApjjq-2M4Za"
      },
      "source": [
        "**To do 4.4 : Define Optimisers and Loss functions**\n",
        "\n",
        "Now initialise your choice of optimiser and loss function. For optimiser we suggest the SGD optimizer with momentum and learning rate 0.01 (defined above). \n",
        "\n",
        "**What is an appropriate loss function for multi-class classification?**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1Jnta9wUqRu"
      },
      "source": [
        "optimizer =  None\n",
        "loss_function = None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxNwcbqNUxZU"
      },
      "source": [
        "**To do 4.5 Train and Validate**\n",
        "\n",
        "Now we define a train and a test function, which should look rather similar.\n",
        "\n",
        "They do the following, in order:\n",
        "\n",
        "- grab a batch of data\n",
        "- zero all gradients (train only)\n",
        "- pass the data through the network\n",
        "- evaluate the loss and record it (if necessary)\n",
        "- backpropagate the loss and update the parameters (train only)\n",
        "\n",
        "**To do check you know what each line in these functions is doing!**\n",
        "\n",
        "Comment each line of code to check you know what each function is doing. What is different about the two functions?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvIREVNiU-su"
      },
      "source": [
        "def train(epoch, log_interval=200):\n",
        "    # Set model to training mode\n",
        "    model.train()\n",
        "    \n",
        "    # Loop over each batch from the training set\n",
        "    # enumerate is an iterator similar to iter() \n",
        "    #except that it also gives the batch number \n",
        "    for batch_number, (images, labels) in enumerate(train_loader):\n",
        "        \n",
        "        # Copy data to GPU if needed\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        # Zero all the gradients before each batch\n",
        "        optimizer.zero_grad() \n",
        "        \n",
        "        # Pass the data through the network\n",
        "        output = model(images)\n",
        "\n",
        "        # Calculate loss\n",
        "        loss = loss_function(output, labels)\n",
        "\n",
        "        # Backpropagate\n",
        "        loss.backward()\n",
        "        \n",
        "        # Update weights\n",
        "        optimizer.step()\n",
        "        \n",
        "        if batch_number % log_interval == 0: \n",
        "            # print the loss every 'log_interval' batch\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_number * len(images), len(train_loader.dataset),\n",
        "                100. * batch_number / len(train_loader), loss.data.item()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNp0w0ZgU_Xt"
      },
      "source": [
        "def validate(loss_vector, accuracy_vector):\n",
        "    # Set the model to evaluate mode. \n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    val_loss, correct = 0, 0\n",
        "    for images, labels in test_loader:\n",
        "        # again the data is copied to the GPU if needed\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        # pass the images to the model\n",
        "        \n",
        "        output = model(images)\n",
        "        \n",
        "        # here we are intersted in the total loss\n",
        "        val_loss += loss_function(output, labels).data.item()  \n",
        "        \n",
        "        # get the index of the max log-probability\n",
        "        pred = output.data.max(1)[1] \n",
        "        # we sum the cases where the prediction and the label match\n",
        "        # we need this data to be in the cpu to calculate   \n",
        "        correct += pred.eq(labels.data).cpu().sum()\n",
        "                                                   \n",
        "    # now we divide the sum val loss by the total number of validation images\n",
        "    # to give an average validation loss\n",
        "    val_loss /= len(test_loader) \n",
        "                                      \n",
        "    # we store this for possible graphing later\n",
        "    loss_vector.append(val_loss) \n",
        "\n",
        "    \n",
        "    accuracy = 100. * correct.to(torch.float32) / len(test_loader.dataset)  \n",
        "    \n",
        "    accuracy_vector.append(accuracy)\n",
        "    \n",
        "    print('\\nValidation set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        val_loss, correct, len(test_loader.dataset), accuracy))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWc1EpwQV00i"
      },
      "source": [
        "### Train/eval mode\n",
        "\n",
        "Note that it is essential that the model be set to train/eval mode depending on whether its training or validating (being applied to validation/test data). If in eval mode, the gradients will not be calculated, backpropagation will not take place and things like dropout will be set to evaluate mode so the network does not vary in response to the data for different runs.\n",
        "\n",
        "**To do 4.6 Run the training loop**\n",
        "\n",
        "We have set the network to run for 7 epochs but feel free to experiment with this. What happens if you change the number of neurons in the network class?\n",
        "\n",
        "**Note** consider swapping between CPU and GPU hardware to compare runtimes. For a simple problem such as this however, CPU is fine"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96Rf6d_UL9eF"
      },
      "source": [
        "epochs = 7\n",
        "\n",
        "lossv, accv = [], []\n",
        "for epoch in range(1, epochs + 1):\n",
        "    train(epoch)\n",
        "    validate(lossv, accv)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JtQ0LH_EL91r"
      },
      "source": [
        "Finally, we can plot our validation loss and accuracy in a graph to see our progress:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXoacoTvV6iV"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(5,3))\n",
        "plt.plot(np.arange(1,epochs+1), lossv)\n",
        "plt.title('validation loss')\n",
        "\n",
        "plt.figure(figsize=(5,3))\n",
        "plt.plot(np.arange(1,epochs+1), accv)\n",
        "plt.title('validation accuracy');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yaICpU9yV-_Z"
      },
      "source": [
        "Done! We've trained an MLP! Is this a good network? For reference, a test accuracy of below ~97% on MNIST is considered poor."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hideCode": true,
        "hideOutput": false,
        "hidePrompt": false,
        "id": "OqtX8HvkyY35"
      },
      "source": [
        "## References\n",
        "\n",
        "For more reading on this topic see the official PyTorch tutorials https://pytorch.org/tutorials"
      ]
    }
  ]
}